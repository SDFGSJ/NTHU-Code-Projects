{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "(optional)"
      ],
      "metadata": {
        "id": "4hiUrTp2g31d"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "02ixxyXJQRNO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a1572a7d-7f30-49a6-db14-dd3f35a73032"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#print(os.getcwd())\n",
        "os.chdir('/content/drive/MyDrive/Colab Notebooks')\n",
        "print(os.getcwd())\n",
        "#print(os.listdir())"
      ],
      "metadata": {
        "id": "cwb1U7JElJPa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "35343806-2a91-42de-c502-5a5e893d219e"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Colab Notebooks\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **HW5: Brain signal classification**\n",
        "In *HW 5*, you need to finish:\n",
        "\n",
        "1.  Model Implementation Part: Implement LSTM and EEGNet models to predict the label of each samples.\n",
        "\n",
        "2.  Model Competition Part: Implementing a model to reach better accuracy performance."
      ],
      "metadata": {
        "id": "CQX9eCfIcRAn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import math\n",
        "import csv\n",
        "import matplotlib.pyplot as plt\n",
        "# Import the packages you need here\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models, constraints"
      ],
      "metadata": {
        "id": "BKJDTLRvQrnY"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = np.load('data.npz')\n",
        "label = np.load('label.npz')"
      ],
      "metadata": {
        "id": "ZQQylnWHQ4yy"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = data['X_train']\n",
        "X_val = data['X_val']\n",
        "X_test = data['X_test']\n",
        "\n",
        "Y_train = label['Y_train']\n",
        "Y_val = label['Y_val']"
      ],
      "metadata": {
        "id": "3Ype-nIkQ-bf"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape, X_val.shape, X_test.shape"
      ],
      "metadata": {
        "id": "xjPvKG_im7mV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "054e1810-31ae-497e-a84b-7ddbde33c44b"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((604, 22, 200), (152, 22, 200), (190, 22, 200))"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Y_train.shape, Y_val.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X7apA2_-lBjF",
        "outputId": "bbb6bb54-fcf4-40e5-82b0-00f71e915cdd"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((604, 1), (152, 1))"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#print(X_train)\n",
        "#print(Y_train)"
      ],
      "metadata": {
        "id": "oVXn-qk40SFg"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Implementation Part"
      ],
      "metadata": {
        "id": "diYYd3e7eopi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### LSTM"
      ],
      "metadata": {
        "id": "97BpHWOAevWJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Build your model here:\n",
        "epochs = 40\n",
        "model = models.Sequential()\n",
        "model.add(layers.LSTM(150, input_shape = (22, 200)))    #100\n",
        "model.add(layers.Dense(6))\n",
        "\n",
        "model.compile(optimizer = 'adam',\n",
        "              loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits = True),\n",
        "              metrics = ['accuracy'])\n",
        "\n",
        "history = model.fit(X_train, Y_train, epochs = epochs, validation_data = (X_val, Y_val))\n",
        "training_loss = history.history['loss']\n",
        "\n",
        "test_loss, test_acc = model.evaluate(X_val, Y_val, verbose = 2)\n",
        "print(\"test accuracy =\", test_acc)\n",
        "\n",
        "model.summary()\n",
        "\n",
        "# plot the training loss\n",
        "plt.plot(training_loss)\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('iterations = ' + str(epochs))\n",
        "plt.title(\"LSTM training loss\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "xxFGe6YRe7qn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "9e3af662-4cdc-4a75-e1c4-abb82fd1dda3"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/40\n",
            "19/19 [==============================] - 7s 30ms/step - loss: 1.3362 - accuracy: 0.4454 - val_loss: 0.9374 - val_accuracy: 0.7039\n",
            "Epoch 2/40\n",
            "19/19 [==============================] - 0s 9ms/step - loss: 0.7164 - accuracy: 0.7964 - val_loss: 0.7579 - val_accuracy: 0.6776\n",
            "Epoch 3/40\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 0.4502 - accuracy: 0.8957 - val_loss: 0.7104 - val_accuracy: 0.6842\n",
            "Epoch 4/40\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 0.2880 - accuracy: 0.9619 - val_loss: 0.6657 - val_accuracy: 0.7105\n",
            "Epoch 5/40\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 0.1678 - accuracy: 0.9917 - val_loss: 0.5689 - val_accuracy: 0.7763\n",
            "Epoch 6/40\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 0.0983 - accuracy: 1.0000 - val_loss: 0.5524 - val_accuracy: 0.7829\n",
            "Epoch 7/40\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 0.0579 - accuracy: 1.0000 - val_loss: 0.5578 - val_accuracy: 0.7697\n",
            "Epoch 8/40\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 0.0373 - accuracy: 1.0000 - val_loss: 0.5430 - val_accuracy: 0.7895\n",
            "Epoch 9/40\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 0.0268 - accuracy: 1.0000 - val_loss: 0.5275 - val_accuracy: 0.8026\n",
            "Epoch 10/40\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 0.0199 - accuracy: 1.0000 - val_loss: 0.5321 - val_accuracy: 0.7829\n",
            "Epoch 11/40\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 0.0156 - accuracy: 1.0000 - val_loss: 0.5282 - val_accuracy: 0.7829\n",
            "Epoch 12/40\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 0.0123 - accuracy: 1.0000 - val_loss: 0.5161 - val_accuracy: 0.8026\n",
            "Epoch 13/40\n",
            "19/19 [==============================] - 0s 8ms/step - loss: 0.0100 - accuracy: 1.0000 - val_loss: 0.5190 - val_accuracy: 0.8026\n",
            "Epoch 14/40\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 0.0083 - accuracy: 1.0000 - val_loss: 0.5232 - val_accuracy: 0.8026\n",
            "Epoch 15/40\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 0.0070 - accuracy: 1.0000 - val_loss: 0.5143 - val_accuracy: 0.8158\n",
            "Epoch 16/40\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 0.5121 - val_accuracy: 0.8158\n",
            "Epoch 17/40\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 0.5180 - val_accuracy: 0.8092\n",
            "Epoch 18/40\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.5111 - val_accuracy: 0.8026\n",
            "Epoch 19/40\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.5133 - val_accuracy: 0.8092\n",
            "Epoch 20/40\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.5130 - val_accuracy: 0.8026\n",
            "Epoch 21/40\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.5120 - val_accuracy: 0.8026\n",
            "Epoch 22/40\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.5177 - val_accuracy: 0.8026\n",
            "Epoch 23/40\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.5169 - val_accuracy: 0.8092\n",
            "Epoch 24/40\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.5176 - val_accuracy: 0.8026\n",
            "Epoch 25/40\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.5194 - val_accuracy: 0.8092\n",
            "Epoch 26/40\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.5210 - val_accuracy: 0.8026\n",
            "Epoch 27/40\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.5243 - val_accuracy: 0.7961\n",
            "Epoch 28/40\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.5233 - val_accuracy: 0.8026\n",
            "Epoch 29/40\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.5243 - val_accuracy: 0.8092\n",
            "Epoch 30/40\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.5324 - val_accuracy: 0.7829\n",
            "Epoch 31/40\n",
            "19/19 [==============================] - 0s 8ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.5284 - val_accuracy: 0.8026\n",
            "Epoch 32/40\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.5316 - val_accuracy: 0.7895\n",
            "Epoch 33/40\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.5330 - val_accuracy: 0.7895\n",
            "Epoch 34/40\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.5384 - val_accuracy: 0.7895\n",
            "Epoch 35/40\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.5385 - val_accuracy: 0.7895\n",
            "Epoch 36/40\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.5381 - val_accuracy: 0.7895\n",
            "Epoch 37/40\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.5421 - val_accuracy: 0.7895\n",
            "Epoch 38/40\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 9.6397e-04 - accuracy: 1.0000 - val_loss: 0.5451 - val_accuracy: 0.7961\n",
            "Epoch 39/40\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 9.1522e-04 - accuracy: 1.0000 - val_loss: 0.5494 - val_accuracy: 0.7961\n",
            "Epoch 40/40\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 8.6570e-04 - accuracy: 1.0000 - val_loss: 0.5473 - val_accuracy: 0.7895\n",
            "5/5 - 0s - loss: 0.5473 - accuracy: 0.7895 - 32ms/epoch - 6ms/step\n",
            "test accuracy = 0.7894737124443054\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm (LSTM)                 (None, 150)               210600    \n",
            "                                                                 \n",
            " dense (Dense)               (None, 6)                 906       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 211,506\n",
            "Trainable params: 211,506\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lstm_pred_test = model.predict(X_test)\n",
        "print(lstm_pred_test)\n",
        "lstm_pred_test = np.argmax(lstm_pred_test, axis = 1).reshape(190, 1).astype(int)\n",
        "print(lstm_pred_test)\n",
        "print(lstm_pred_test.shape)\n",
        "print(lstm_pred_test.dtype)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QbgyJzBYTx-r",
        "outputId": "842823df-c736-433c-ddbb-9c4491317ecb"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6/6 [==============================] - 0s 3ms/step\n",
            "[[ 2.3601604   1.232605    2.2881181  -3.601222   -1.2461982   0.6650446 ]\n",
            " [-2.6669695  -2.9929025  -3.327166    5.4006667   2.7681518   0.17301017]\n",
            " [-2.648839    1.348983   -1.7326144   3.3711758   2.5213466  -0.91494495]\n",
            " ...\n",
            " [ 3.2818143   6.1600685  -3.491572   -1.5146071   0.05731051 -2.376657  ]\n",
            " [ 3.6008213   5.142181   -1.6647666  -2.4641047  -2.1527858  -0.48689964]\n",
            " [ 1.8020871   6.2058606  -2.9597101  -0.70687914 -1.0871023  -1.3008788 ]]\n",
            "[[0]\n",
            " [3]\n",
            " [3]\n",
            " [2]\n",
            " [5]\n",
            " [1]\n",
            " [1]\n",
            " [2]\n",
            " [5]\n",
            " [0]\n",
            " [2]\n",
            " [2]\n",
            " [0]\n",
            " [5]\n",
            " [0]\n",
            " [3]\n",
            " [5]\n",
            " [5]\n",
            " [3]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [5]\n",
            " [5]\n",
            " [4]\n",
            " [3]\n",
            " [2]\n",
            " [1]\n",
            " [0]\n",
            " [2]\n",
            " [5]\n",
            " [1]\n",
            " [0]\n",
            " [2]\n",
            " [2]\n",
            " [0]\n",
            " [5]\n",
            " [0]\n",
            " [2]\n",
            " [2]\n",
            " [4]\n",
            " [1]\n",
            " [4]\n",
            " [4]\n",
            " [2]\n",
            " [1]\n",
            " [3]\n",
            " [0]\n",
            " [3]\n",
            " [2]\n",
            " [2]\n",
            " [4]\n",
            " [4]\n",
            " [3]\n",
            " [4]\n",
            " [3]\n",
            " [5]\n",
            " [2]\n",
            " [0]\n",
            " [1]\n",
            " [4]\n",
            " [5]\n",
            " [1]\n",
            " [2]\n",
            " [4]\n",
            " [3]\n",
            " [1]\n",
            " [2]\n",
            " [0]\n",
            " [4]\n",
            " [5]\n",
            " [4]\n",
            " [5]\n",
            " [3]\n",
            " [2]\n",
            " [3]\n",
            " [4]\n",
            " [4]\n",
            " [3]\n",
            " [2]\n",
            " [1]\n",
            " [3]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [3]\n",
            " [3]\n",
            " [1]\n",
            " [1]\n",
            " [4]\n",
            " [2]\n",
            " [5]\n",
            " [0]\n",
            " [2]\n",
            " [4]\n",
            " [1]\n",
            " [0]\n",
            " [5]\n",
            " [2]\n",
            " [5]\n",
            " [3]\n",
            " [4]\n",
            " [3]\n",
            " [0]\n",
            " [3]\n",
            " [4]\n",
            " [1]\n",
            " [2]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [5]\n",
            " [2]\n",
            " [4]\n",
            " [4]\n",
            " [4]\n",
            " [1]\n",
            " [4]\n",
            " [1]\n",
            " [1]\n",
            " [5]\n",
            " [5]\n",
            " [3]\n",
            " [0]\n",
            " [3]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [3]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [2]\n",
            " [4]\n",
            " [5]\n",
            " [2]\n",
            " [1]\n",
            " [3]\n",
            " [3]\n",
            " [1]\n",
            " [0]\n",
            " [2]\n",
            " [5]\n",
            " [4]\n",
            " [1]\n",
            " [3]\n",
            " [3]\n",
            " [3]\n",
            " [1]\n",
            " [5]\n",
            " [3]\n",
            " [1]\n",
            " [2]\n",
            " [1]\n",
            " [1]\n",
            " [2]\n",
            " [0]\n",
            " [2]\n",
            " [3]\n",
            " [1]\n",
            " [1]\n",
            " [3]\n",
            " [5]\n",
            " [1]\n",
            " [5]\n",
            " [2]\n",
            " [5]\n",
            " [3]\n",
            " [1]\n",
            " [2]\n",
            " [2]\n",
            " [5]\n",
            " [2]\n",
            " [4]\n",
            " [4]\n",
            " [1]\n",
            " [4]\n",
            " [0]\n",
            " [4]\n",
            " [2]\n",
            " [3]\n",
            " [4]\n",
            " [2]\n",
            " [4]\n",
            " [0]\n",
            " [5]\n",
            " [1]\n",
            " [1]\n",
            " [1]]\n",
            "(190, 1)\n",
            "int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output = lstm_pred_test\n",
        "assert(output.shape == (190, 1))\n",
        "np.savetxt('lstm_output.csv', output, fmt=\"%d\", delimiter=\",\")"
      ],
      "metadata": {
        "id": "sIXH_6BHjm6w"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### EEGNet"
      ],
      "metadata": {
        "id": "xSGZPbDHrfOr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Build your model here:\n",
        "def EEGNet(nb_classes, Chans = 64, Samples = 128, \n",
        "             dropoutRate = 0.5, kernLength = 64, F1 = 8, \n",
        "             D = 2, F2 = 16, norm_rate = 0.25, dropoutType = 'Dropout'):\n",
        "    \"\"\" Keras Implementation of EEGNet\n",
        "    http://iopscience.iop.org/article/10.1088/1741-2552/aace8c/meta\n",
        "    Note that this implements the newest version of EEGNet and NOT the earlier\n",
        "    version (version v1 and v2 on arxiv). We strongly recommend using this\n",
        "    architecture as it performs much better and has nicer properties than\n",
        "    our earlier version. For example:\n",
        "        \n",
        "        1. Depthwise Convolutions to learn spatial filters within a \n",
        "        temporal convolution. The use of the depth_multiplier option maps \n",
        "        exactly to the number of spatial filters learned within a temporal\n",
        "        filter. This matches the setup of algorithms like FBCSP which learn \n",
        "        spatial filters within each filter in a filter-bank. This also limits \n",
        "        the number of free parameters to fit when compared to a fully-connected\n",
        "        convolution. \n",
        "        \n",
        "        2. Separable Convolutions to learn how to optimally combine spatial\n",
        "        filters across temporal bands. Separable Convolutions are Depthwise\n",
        "        Convolutions followed by (1x1) Pointwise Convolutions. \n",
        "        \n",
        "    \n",
        "    While the original paper used Dropout, we found that SpatialDropout2D \n",
        "    sometimes produced slightly better results for classification of ERP \n",
        "    signals. However, SpatialDropout2D significantly reduced performance \n",
        "    on the Oscillatory dataset (SMR, BCI-IV Dataset 2A). We recommend using\n",
        "    the default Dropout in most cases.\n",
        "        \n",
        "    Assumes the input signal is sampled at 128Hz. If you want to use this model\n",
        "    for any other sampling rate you will need to modify the lengths of temporal\n",
        "    kernels and average pooling size in blocks 1 and 2 as needed (double the \n",
        "    kernel lengths for double the sampling rate, etc). Note that we haven't \n",
        "    tested the model performance with this rule so this may not work well. \n",
        "    \n",
        "    The model with default parameters gives the EEGNet-8,2 model as discussed\n",
        "    in the paper. This model should do pretty well in general, although it is\n",
        "\tadvised to do some model searching to get optimal performance on your\n",
        "\tparticular dataset.\n",
        "    We set F2 = F1 * D (number of input filters = number of output filters) for\n",
        "    the SeparableConv2D layer. We haven't extensively tested other values of this\n",
        "    parameter (say, F2 < F1 * D for compressed learning, and F2 > F1 * D for\n",
        "    overcomplete). We believe the main parameters to focus on are F1 and D. \n",
        "    Inputs:\n",
        "        \n",
        "      nb_classes      : int, number of classes to classify\n",
        "      Chans, Samples  : number of channels and time points in the EEG data\n",
        "      dropoutRate     : dropout fraction\n",
        "      kernLength      : length of temporal convolution in first layer. We found\n",
        "                        that setting this to be half the sampling rate worked\n",
        "                        well in practice. For the SMR dataset in particular\n",
        "                        since the data was high-passed at 4Hz we used a kernel\n",
        "                        length of 32.     \n",
        "      F1, F2          : number of temporal filters (F1) and number of pointwise\n",
        "                        filters (F2) to learn. Default: F1 = 8, F2 = F1 * D. \n",
        "      D               : number of spatial filters to learn within each temporal\n",
        "                        convolution. Default: D = 2\n",
        "      dropoutType     : Either SpatialDropout2D or Dropout, passed as a string.\n",
        "    \"\"\"\n",
        "    \n",
        "    if dropoutType == 'SpatialDropout2D':\n",
        "        dropoutType = layers.SpatialDropout2D\n",
        "    elif dropoutType == 'Dropout':\n",
        "        dropoutType = layers.Dropout\n",
        "    else:\n",
        "        raise ValueError('dropoutType must be one of SpatialDropout2D '\n",
        "                         'or Dropout, passed as a string.')\n",
        "    \n",
        "    input1   = layers.Input(shape = (Chans, Samples, 1))\n",
        "\n",
        "    ##################################################################\n",
        "    block1       = layers.Conv2D(F1, (1, kernLength), padding = 'same',\n",
        "                                   input_shape = (Chans, Samples, 1),\n",
        "                                   use_bias = False)(input1)\n",
        "    block1       = layers.BatchNormalization()(block1)\n",
        "    block1       = layers.DepthwiseConv2D((Chans, 1), use_bias = False, \n",
        "                                   depth_multiplier = D,\n",
        "                                   depthwise_constraint = constraints.max_norm(1.))(block1)\n",
        "    block1       = layers.BatchNormalization()(block1)\n",
        "    block1       = layers.Activation('elu')(block1)\n",
        "    block1       = layers.AveragePooling2D((1, 4))(block1)\n",
        "    block1       = dropoutType(dropoutRate)(block1)\n",
        "    \n",
        "    block2       = layers.SeparableConv2D(F2, (1, 16),\n",
        "                                   use_bias = False, padding = 'same')(block1)\n",
        "    block2       = layers.BatchNormalization()(block2)\n",
        "    block2       = layers.Activation('elu')(block2)\n",
        "    block2       = layers.AveragePooling2D((1, 8))(block2)\n",
        "    block2       = dropoutType(dropoutRate)(block2)\n",
        "        \n",
        "    flatten      = layers.Flatten(name = 'flatten')(block2)\n",
        "    \n",
        "    dense        = layers.Dense(nb_classes, name = 'dense', \n",
        "                         kernel_constraint = constraints.max_norm(norm_rate))(flatten)\n",
        "    softmax      = layers.Activation('softmax', name = 'softmax')(dense)\n",
        "    \n",
        "    return models.Model(inputs=input1, outputs=softmax)"
      ],
      "metadata": {
        "id": "OCUyBSH1hvqG"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 40\n",
        "EEGNet_model = EEGNet(\n",
        "    nb_classes = 6,\n",
        "    Chans = 22,\n",
        "    Samples = 200,\n",
        "    kernLength = 100\n",
        ")\n",
        "\n",
        "EEGNet_model.compile(optimizer = 'adam',\n",
        "              loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits = True),\n",
        "              metrics = ['accuracy'])\n",
        "\n",
        "history = EEGNet_model.fit(X_train, Y_train, epochs = epochs, validation_data = (X_val, Y_val))\n",
        "training_loss = history.history['loss']\n",
        "\n",
        "test_loss, test_acc = EEGNet_model.evaluate(X_val, Y_val, verbose = 2)\n",
        "print(\"test accuracy =\", test_acc)\n",
        "\n",
        "EEGNet_model.summary()\n",
        "\n",
        "# plot the training loss\n",
        "plt.plot(training_loss)\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('iterations = ' + str(epochs))\n",
        "plt.title(\"EEGNet training loss\")\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "IDdb06EwH_CL",
        "outputId": "ac27c47e-7d4e-4f6c-8cab-76bfd9e92fac"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/40\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/tensorflow/python/util/dispatch.py:1082: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
            "  return dispatch_target(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "19/19 [==============================] - 5s 25ms/step - loss: 1.7510 - accuracy: 0.2632 - val_loss: 1.6760 - val_accuracy: 0.6053\n",
            "Epoch 2/40\n",
            "19/19 [==============================] - 0s 9ms/step - loss: 1.5892 - accuracy: 0.4851 - val_loss: 1.5858 - val_accuracy: 0.7237\n",
            "Epoch 3/40\n",
            "19/19 [==============================] - 0s 9ms/step - loss: 1.4268 - accuracy: 0.6474 - val_loss: 1.5083 - val_accuracy: 0.7895\n",
            "Epoch 4/40\n",
            "19/19 [==============================] - 0s 9ms/step - loss: 1.2091 - accuracy: 0.7666 - val_loss: 1.3696 - val_accuracy: 0.7961\n",
            "Epoch 5/40\n",
            "19/19 [==============================] - 0s 8ms/step - loss: 1.0360 - accuracy: 0.8046 - val_loss: 1.2190 - val_accuracy: 0.8224\n",
            "Epoch 6/40\n",
            "19/19 [==============================] - 0s 8ms/step - loss: 0.9098 - accuracy: 0.8361 - val_loss: 1.1048 - val_accuracy: 0.8421\n",
            "Epoch 7/40\n",
            "19/19 [==============================] - 0s 8ms/step - loss: 0.8458 - accuracy: 0.8427 - val_loss: 1.0089 - val_accuracy: 0.8684\n",
            "Epoch 8/40\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.8001 - accuracy: 0.8758 - val_loss: 0.9594 - val_accuracy: 0.8882\n",
            "Epoch 9/40\n",
            "19/19 [==============================] - 0s 8ms/step - loss: 0.7690 - accuracy: 0.8709 - val_loss: 0.9122 - val_accuracy: 0.8816\n",
            "Epoch 10/40\n",
            "19/19 [==============================] - 0s 8ms/step - loss: 0.7308 - accuracy: 0.8957 - val_loss: 0.8753 - val_accuracy: 0.9013\n",
            "Epoch 11/40\n",
            "19/19 [==============================] - 0s 9ms/step - loss: 0.7140 - accuracy: 0.9007 - val_loss: 0.8110 - val_accuracy: 0.9013\n",
            "Epoch 12/40\n",
            "19/19 [==============================] - 0s 8ms/step - loss: 0.6749 - accuracy: 0.9073 - val_loss: 0.7753 - val_accuracy: 0.9145\n",
            "Epoch 13/40\n",
            "19/19 [==============================] - 0s 9ms/step - loss: 0.6581 - accuracy: 0.9106 - val_loss: 0.7538 - val_accuracy: 0.9145\n",
            "Epoch 14/40\n",
            "19/19 [==============================] - 0s 8ms/step - loss: 0.6573 - accuracy: 0.9238 - val_loss: 0.7191 - val_accuracy: 0.9211\n",
            "Epoch 15/40\n",
            "19/19 [==============================] - 0s 8ms/step - loss: 0.6403 - accuracy: 0.9089 - val_loss: 0.6890 - val_accuracy: 0.9276\n",
            "Epoch 16/40\n",
            "19/19 [==============================] - 0s 8ms/step - loss: 0.6231 - accuracy: 0.9288 - val_loss: 0.6697 - val_accuracy: 0.9408\n",
            "Epoch 17/40\n",
            "19/19 [==============================] - 0s 8ms/step - loss: 0.5912 - accuracy: 0.9238 - val_loss: 0.6358 - val_accuracy: 0.9539\n",
            "Epoch 18/40\n",
            "19/19 [==============================] - 0s 8ms/step - loss: 0.5849 - accuracy: 0.9371 - val_loss: 0.6039 - val_accuracy: 0.9539\n",
            "Epoch 19/40\n",
            "19/19 [==============================] - 0s 8ms/step - loss: 0.5878 - accuracy: 0.9222 - val_loss: 0.5586 - val_accuracy: 0.9474\n",
            "Epoch 20/40\n",
            "19/19 [==============================] - 0s 8ms/step - loss: 0.5617 - accuracy: 0.9338 - val_loss: 0.5581 - val_accuracy: 0.9737\n",
            "Epoch 21/40\n",
            "19/19 [==============================] - 0s 8ms/step - loss: 0.5469 - accuracy: 0.9437 - val_loss: 0.5326 - val_accuracy: 0.9671\n",
            "Epoch 22/40\n",
            "19/19 [==============================] - 0s 8ms/step - loss: 0.5512 - accuracy: 0.9487 - val_loss: 0.5374 - val_accuracy: 0.9737\n",
            "Epoch 23/40\n",
            "19/19 [==============================] - 0s 8ms/step - loss: 0.5223 - accuracy: 0.9338 - val_loss: 0.5097 - val_accuracy: 0.9803\n",
            "Epoch 24/40\n",
            "19/19 [==============================] - 0s 8ms/step - loss: 0.5192 - accuracy: 0.9487 - val_loss: 0.4885 - val_accuracy: 0.9737\n",
            "Epoch 25/40\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 0.4993 - accuracy: 0.9536 - val_loss: 0.4716 - val_accuracy: 0.9868\n",
            "Epoch 26/40\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 0.4938 - accuracy: 0.9553 - val_loss: 0.4853 - val_accuracy: 0.9868\n",
            "Epoch 27/40\n",
            "19/19 [==============================] - 0s 8ms/step - loss: 0.4915 - accuracy: 0.9570 - val_loss: 0.4647 - val_accuracy: 0.9803\n",
            "Epoch 28/40\n",
            "19/19 [==============================] - 0s 8ms/step - loss: 0.4859 - accuracy: 0.9470 - val_loss: 0.4382 - val_accuracy: 0.9868\n",
            "Epoch 29/40\n",
            "19/19 [==============================] - 0s 8ms/step - loss: 0.4723 - accuracy: 0.9586 - val_loss: 0.4314 - val_accuracy: 0.9868\n",
            "Epoch 30/40\n",
            "19/19 [==============================] - 0s 9ms/step - loss: 0.4736 - accuracy: 0.9354 - val_loss: 0.3977 - val_accuracy: 0.9934\n",
            "Epoch 31/40\n",
            "19/19 [==============================] - 0s 8ms/step - loss: 0.4465 - accuracy: 0.9586 - val_loss: 0.4031 - val_accuracy: 0.9934\n",
            "Epoch 32/40\n",
            "19/19 [==============================] - 0s 8ms/step - loss: 0.4467 - accuracy: 0.9652 - val_loss: 0.3935 - val_accuracy: 0.9868\n",
            "Epoch 33/40\n",
            "19/19 [==============================] - 0s 8ms/step - loss: 0.4500 - accuracy: 0.9437 - val_loss: 0.3737 - val_accuracy: 0.9934\n",
            "Epoch 34/40\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 0.4362 - accuracy: 0.9702 - val_loss: 0.3693 - val_accuracy: 0.9934\n",
            "Epoch 35/40\n",
            "19/19 [==============================] - 0s 8ms/step - loss: 0.4130 - accuracy: 0.9652 - val_loss: 0.3591 - val_accuracy: 0.9868\n",
            "Epoch 36/40\n",
            "19/19 [==============================] - 0s 8ms/step - loss: 0.4112 - accuracy: 0.9619 - val_loss: 0.3611 - val_accuracy: 0.9934\n",
            "Epoch 37/40\n",
            "19/19 [==============================] - 0s 8ms/step - loss: 0.4088 - accuracy: 0.9735 - val_loss: 0.3574 - val_accuracy: 0.9934\n",
            "Epoch 38/40\n",
            "19/19 [==============================] - 0s 8ms/step - loss: 0.4027 - accuracy: 0.9685 - val_loss: 0.3467 - val_accuracy: 0.9803\n",
            "Epoch 39/40\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 0.4047 - accuracy: 0.9487 - val_loss: 0.3341 - val_accuracy: 0.9737\n",
            "Epoch 40/40\n",
            "19/19 [==============================] - 0s 8ms/step - loss: 0.3925 - accuracy: 0.9685 - val_loss: 0.3411 - val_accuracy: 0.9803\n",
            "5/5 - 0s - loss: 0.3411 - accuracy: 0.9803 - 28ms/epoch - 6ms/step\n",
            "test accuracy = 0.9802631735801697\n",
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 22, 200, 1)]      0         \n",
            "                                                                 \n",
            " conv2d (Conv2D)             (None, 22, 200, 8)        800       \n",
            "                                                                 \n",
            " batch_normalization (BatchN  (None, 22, 200, 8)       32        \n",
            " ormalization)                                                   \n",
            "                                                                 \n",
            " depthwise_conv2d (Depthwise  (None, 1, 200, 16)       352       \n",
            " Conv2D)                                                         \n",
            "                                                                 \n",
            " batch_normalization_1 (Batc  (None, 1, 200, 16)       64        \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " activation (Activation)     (None, 1, 200, 16)        0         \n",
            "                                                                 \n",
            " average_pooling2d (AverageP  (None, 1, 50, 16)        0         \n",
            " ooling2D)                                                       \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 1, 50, 16)         0         \n",
            "                                                                 \n",
            " separable_conv2d (Separable  (None, 1, 50, 16)        512       \n",
            " Conv2D)                                                         \n",
            "                                                                 \n",
            " batch_normalization_2 (Batc  (None, 1, 50, 16)        64        \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " activation_1 (Activation)   (None, 1, 50, 16)         0         \n",
            "                                                                 \n",
            " average_pooling2d_1 (Averag  (None, 1, 6, 16)         0         \n",
            " ePooling2D)                                                     \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 1, 6, 16)          0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 96)                0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 6)                 582       \n",
            "                                                                 \n",
            " softmax (Activation)        (None, 6)                 0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,406\n",
            "Trainable params: 2,326\n",
            "Non-trainable params: 80\n",
            "_________________________________________________________________\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "EEGNet_pred_test = EEGNet_model.predict(X_test)\n",
        "print(EEGNet_pred_test)\n",
        "EEGNet_pred_test = np.argmax(EEGNet_pred_test, axis = 1).reshape(190, 1).astype(int)\n",
        "print(EEGNet_pred_test)\n",
        "print(EEGNet_pred_test.shape)\n",
        "print(EEGNet_pred_test.dtype)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dkn3up97KAHK",
        "outputId": "0d664e2d-e4db-47b6-f556-f7f585745d67"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6/6 [==============================] - 0s 8ms/step\n",
            "[[0.55310357 0.05444532 0.18967566 0.12341889 0.02030161 0.05905503]\n",
            " [0.06794696 0.00728915 0.01282991 0.77068156 0.11297533 0.02827712]\n",
            " [0.01331148 0.03480061 0.01731132 0.26134583 0.6146143  0.05861649]\n",
            " ...\n",
            " [0.03135946 0.7567958  0.05567298 0.007553   0.118435   0.03018381]\n",
            " [0.6856611  0.10685781 0.11082686 0.04968324 0.01276192 0.03420906]\n",
            " [0.14785004 0.6020544  0.10350221 0.02829686 0.0908485  0.02744793]]\n",
            "[[0]\n",
            " [3]\n",
            " [4]\n",
            " [2]\n",
            " [5]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [5]\n",
            " [1]\n",
            " [2]\n",
            " [0]\n",
            " [0]\n",
            " [5]\n",
            " [5]\n",
            " [3]\n",
            " [5]\n",
            " [5]\n",
            " [3]\n",
            " [5]\n",
            " [1]\n",
            " [1]\n",
            " [5]\n",
            " [5]\n",
            " [4]\n",
            " [3]\n",
            " [2]\n",
            " [1]\n",
            " [0]\n",
            " [2]\n",
            " [5]\n",
            " [3]\n",
            " [0]\n",
            " [0]\n",
            " [2]\n",
            " [0]\n",
            " [5]\n",
            " [5]\n",
            " [2]\n",
            " [2]\n",
            " [4]\n",
            " [0]\n",
            " [4]\n",
            " [4]\n",
            " [2]\n",
            " [0]\n",
            " [3]\n",
            " [0]\n",
            " [4]\n",
            " [2]\n",
            " [2]\n",
            " [4]\n",
            " [4]\n",
            " [3]\n",
            " [4]\n",
            " [0]\n",
            " [5]\n",
            " [2]\n",
            " [3]\n",
            " [1]\n",
            " [3]\n",
            " [5]\n",
            " [1]\n",
            " [2]\n",
            " [4]\n",
            " [3]\n",
            " [1]\n",
            " [2]\n",
            " [0]\n",
            " [4]\n",
            " [5]\n",
            " [4]\n",
            " [0]\n",
            " [3]\n",
            " [1]\n",
            " [3]\n",
            " [3]\n",
            " [4]\n",
            " [3]\n",
            " [2]\n",
            " [1]\n",
            " [4]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [3]\n",
            " [4]\n",
            " [1]\n",
            " [1]\n",
            " [4]\n",
            " [2]\n",
            " [5]\n",
            " [5]\n",
            " [2]\n",
            " [4]\n",
            " [1]\n",
            " [0]\n",
            " [5]\n",
            " [2]\n",
            " [5]\n",
            " [3]\n",
            " [4]\n",
            " [3]\n",
            " [2]\n",
            " [4]\n",
            " [4]\n",
            " [1]\n",
            " [2]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [2]\n",
            " [4]\n",
            " [3]\n",
            " [3]\n",
            " [1]\n",
            " [4]\n",
            " [1]\n",
            " [1]\n",
            " [5]\n",
            " [5]\n",
            " [3]\n",
            " [1]\n",
            " [3]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [3]\n",
            " [1]\n",
            " [0]\n",
            " [5]\n",
            " [0]\n",
            " [2]\n",
            " [3]\n",
            " [2]\n",
            " [2]\n",
            " [0]\n",
            " [3]\n",
            " [3]\n",
            " [5]\n",
            " [0]\n",
            " [2]\n",
            " [5]\n",
            " [4]\n",
            " [0]\n",
            " [3]\n",
            " [3]\n",
            " [0]\n",
            " [1]\n",
            " [5]\n",
            " [3]\n",
            " [1]\n",
            " [2]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [2]\n",
            " [3]\n",
            " [1]\n",
            " [1]\n",
            " [3]\n",
            " [5]\n",
            " [0]\n",
            " [5]\n",
            " [5]\n",
            " [5]\n",
            " [4]\n",
            " [1]\n",
            " [2]\n",
            " [1]\n",
            " [5]\n",
            " [2]\n",
            " [4]\n",
            " [4]\n",
            " [1]\n",
            " [4]\n",
            " [0]\n",
            " [4]\n",
            " [2]\n",
            " [3]\n",
            " [4]\n",
            " [2]\n",
            " [4]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]]\n",
            "(190, 1)\n",
            "int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output = EEGNet_pred_test\n",
        "assert(output.shape == (190, 1))\n",
        "np.savetxt('eegnet_output.csv', output, fmt=\"%d\", delimiter=\",\")"
      ],
      "metadata": {
        "id": "Ge8jZUU8gve3"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Competition Part"
      ],
      "metadata": {
        "id": "qnHnQ_yVerBo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Build your model here:\n"
      ],
      "metadata": {
        "id": "zlhO90b9iB_-"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output = EEGNet_pred_test\n",
        "assert(output.shape == (190, 1))\n",
        "np.savetxt('competition_output.csv', output, fmt=\"%d\", delimiter=\",\")"
      ],
      "metadata": {
        "id": "m097nvkXiIqY"
      },
      "execution_count": 17,
      "outputs": []
    }
  ]
}